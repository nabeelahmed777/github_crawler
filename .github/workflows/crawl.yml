name: GitHub Repository Crawler

on:
  workflow_dispatch:  # Manual trigger

jobs:
  crawl:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:13
        env:
          POSTGRES_PASSWORD: password
          POSTGRES_DB: github_data
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install psycopg2-binary==2.9.5 requests==2.28.2 python-dotenv==0.19.2 pandas==1.5.3

    - name: Setup database
      env:
        DB_HOST: localhost
        DB_PORT: 5432
        DB_NAME: github_data
        DB_USER: postgres
        DB_PASSWORD: password  
      run: |
        python scripts/setup_database.py

    - name: Run crawler
      env:
        DB_HOST: localhost
        DB_PORT: 5432
        DB_NAME: github_data
        DB_USER: postgres
        DB_PASSWORD: password  
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        python main.py

    - name: Upload success
      run: |
        echo "ðŸŽ‰ GitHub Repository Crawler completed successfully!"